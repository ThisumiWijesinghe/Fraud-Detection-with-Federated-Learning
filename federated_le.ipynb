{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThisumiWijesinghe/Fraud-Detection-with-Federated-Learning/blob/main/federated_le.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwi-_p9CtVuf",
        "outputId": "ab349392-f3b0-440c-bb58-085e5c95a4bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'paysim1' dataset.\n",
            "Dataset shape: (6362620, 11)\n",
            "\n",
            "Fraud samples per client:\n",
            "\n",
            "Client 1: Fraud samples = 372, Total samples = 258223\n",
            "Client 2: Fraud samples = 1753, Total samples = 51178\n",
            "Client 3: Fraud samples = 65, Total samples = 478277\n",
            "Client 4: Fraud samples = 8, Total samples = 5254\n",
            "Client 5: Fraud samples = 1000, Total samples = 4192294\n",
            "Client 6: Fraud samples = 1, Total samples = 115029\n",
            "Client 7: Fraud samples = 2912, Total samples = 663175\n",
            "Client 8: Fraud samples = 88, Total samples = 18551\n",
            "Client 9: Fraud samples = 246, Total samples = 1712\n",
            "Client 10: Fraud samples = 497, Total samples = 83514\n",
            "Client 11: Fraud samples = 1044, Total samples = 121495\n",
            "Client 12: Fraud samples = 227, Total samples = 373918\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import kagglehub\n",
        "\n",
        "# ================================\n",
        "# Step 1: Load PaySim Dataset\n",
        "# ================================\n",
        "\n",
        "path = kagglehub.dataset_download(\"ealaxi/paysim1\")\n",
        "file_path = path + \"/PS_20174392719_1491204439457_log.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "\n",
        "# ================================\n",
        "# Step 2: Basic Preprocessing\n",
        "# ================================\n",
        "\n",
        "# Encode transaction type\n",
        "le = LabelEncoder()\n",
        "df[\"type\"] = le.fit_transform(df[\"type\"])\n",
        "\n",
        "# Target column\n",
        "target_col = \"isFraud\"\n",
        "\n",
        "# Features\n",
        "feature_cols = [\n",
        "    \"step\", \"type\", \"amount\",\n",
        "    \"oldbalanceOrg\", \"newbalanceOrig\",\n",
        "    \"oldbalanceDest\", \"newbalanceDest\"\n",
        "]\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df[target_col]\n",
        "\n",
        "# ================================\n",
        "# Step 3: Dirichlet Non-IID Split\n",
        "# ================================\n",
        "\n",
        "NUM_CLIENTS = 12\n",
        "ALPHA = 0.5   # smaller = more non-IID\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Separate fraud and non-fraud indices\n",
        "fraud_idx = np.where(y == 1)[0]\n",
        "nonfraud_idx = np.where(y == 0)[0]\n",
        "\n",
        "# Dirichlet distribution\n",
        "fraud_dist = np.random.dirichlet([ALPHA] * NUM_CLIENTS)\n",
        "nonfraud_dist = np.random.dirichlet([ALPHA] * NUM_CLIENTS)\n",
        "\n",
        "# Split indices\n",
        "fraud_splits = np.split(\n",
        "    fraud_idx,\n",
        "    (np.cumsum(fraud_dist)[:-1] * len(fraud_idx)).astype(int)\n",
        ")\n",
        "\n",
        "nonfraud_splits = np.split(\n",
        "    nonfraud_idx,\n",
        "    (np.cumsum(nonfraud_dist)[:-1] * len(nonfraud_idx)).astype(int)\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# Step 4: Create Client Datasets\n",
        "# ================================\n",
        "\n",
        "clients_data = {}\n",
        "\n",
        "for i in range(NUM_CLIENTS):\n",
        "    client_indices = np.concatenate(\n",
        "        [fraud_splits[i], nonfraud_splits[i]]\n",
        "    )\n",
        "    np.random.shuffle(client_indices)\n",
        "\n",
        "    clients_data[i] = {\n",
        "        \"X\": X.iloc[client_indices],\n",
        "        \"y\": y.iloc[client_indices]\n",
        "    }\n",
        "\n",
        "# ================================\n",
        "# Step 5: Print Fraud Samples per Client\n",
        "# ================================\n",
        "\n",
        "print(\"\\nFraud samples per client:\\n\")\n",
        "\n",
        "for i in range(NUM_CLIENTS):\n",
        "    fraud_count = np.sum(clients_data[i][\"y\"] == 1)\n",
        "    total_samples = len(clients_data[i][\"y\"])\n",
        "    print(f\"Client {i+1}: Fraud samples = {fraud_count}, Total samples = {total_samples}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMOBYcsO_azj"
      },
      "source": [
        "##Define DNN Model (Server & Clients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JD4UBpW5vAjM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "INPUT_DIM = len(feature_cols)\n",
        "\n",
        "def create_dnn_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(INPUT_DIM,)),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(32, activation=\"relu\"),\n",
        "        layers.Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(0.001),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9eDrt_t_hve"
      },
      "source": [
        "##Server Initializes Global Model (EMPTY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tAUsFEGa_G5Y"
      },
      "outputs": [],
      "source": [
        "global_model = create_dnn_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8jjTUM__n8m"
      },
      "source": [
        "##FedAvg Aggregation Function (Server Side)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SjpqhS9T_K8T"
      },
      "outputs": [],
      "source": [
        "def fedavg(client_weights):\n",
        "    avg_weights = []\n",
        "    for weights in zip(*client_weights):\n",
        "        avg_weights.append(np.mean(weights, axis=0))\n",
        "    return avg_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_ykmBz9_1OO"
      },
      "source": [
        "##Federated Training Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zZEyctu6_Opl"
      },
      "outputs": [],
      "source": [
        "NUM_ROUNDS = 100       # Global rounds\n",
        "LOCAL_EPOCHS = 4     # Client training\n",
        "BATCH_SIZE = 1024\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-IlwWoJ_3XL"
      },
      "source": [
        "##FedAvg Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK6PCq2q_UiY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42716f2a-57e7-4aec-b4b8-ee944317ac69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Federated Training using FedAvg\n",
            "\n",
            "--- Global Round 1 ---\n",
            "Global Round 1 completed\n",
            "--- Global Round 2 ---\n",
            "Global Round 2 completed\n",
            "--- Global Round 3 ---\n",
            "Global Round 3 completed\n",
            "--- Global Round 4 ---\n",
            "Global Round 4 completed\n",
            "--- Global Round 5 ---\n",
            "Global Round 5 completed\n",
            "--- Global Round 6 ---\n",
            "Global Round 6 completed\n",
            "--- Global Round 7 ---\n",
            "Global Round 7 completed\n",
            "--- Global Round 8 ---\n",
            "Global Round 8 completed\n",
            "--- Global Round 9 ---\n",
            "Global Round 9 completed\n",
            "--- Global Round 10 ---\n",
            "Global Round 10 completed\n",
            "--- Global Round 11 ---\n",
            "Global Round 11 completed\n",
            "--- Global Round 12 ---\n",
            "Global Round 12 completed\n",
            "--- Global Round 13 ---\n",
            "Global Round 13 completed\n",
            "--- Global Round 14 ---\n",
            "Global Round 14 completed\n",
            "--- Global Round 15 ---\n",
            "Global Round 15 completed\n",
            "--- Global Round 16 ---\n",
            "Global Round 16 completed\n",
            "--- Global Round 17 ---\n",
            "Global Round 17 completed\n",
            "--- Global Round 18 ---\n",
            "Global Round 18 completed\n",
            "--- Global Round 19 ---\n",
            "Global Round 19 completed\n",
            "--- Global Round 20 ---\n",
            "Global Round 20 completed\n",
            "--- Global Round 21 ---\n",
            "Global Round 21 completed\n",
            "--- Global Round 22 ---\n",
            "Global Round 22 completed\n",
            "--- Global Round 23 ---\n",
            "Global Round 23 completed\n",
            "--- Global Round 24 ---\n",
            "Global Round 24 completed\n",
            "--- Global Round 25 ---\n",
            "Global Round 25 completed\n",
            "--- Global Round 26 ---\n",
            "Global Round 26 completed\n",
            "--- Global Round 27 ---\n",
            "Global Round 27 completed\n",
            "--- Global Round 28 ---\n",
            "Global Round 28 completed\n",
            "--- Global Round 29 ---\n",
            "Global Round 29 completed\n",
            "--- Global Round 30 ---\n",
            "Global Round 30 completed\n",
            "--- Global Round 31 ---\n",
            "Global Round 31 completed\n",
            "--- Global Round 32 ---\n",
            "Global Round 32 completed\n",
            "--- Global Round 33 ---\n",
            "Global Round 33 completed\n",
            "--- Global Round 34 ---\n",
            "Global Round 34 completed\n",
            "--- Global Round 35 ---\n",
            "Global Round 35 completed\n",
            "--- Global Round 36 ---\n",
            "Global Round 36 completed\n",
            "--- Global Round 37 ---\n",
            "Global Round 37 completed\n",
            "--- Global Round 38 ---\n",
            "Global Round 38 completed\n",
            "--- Global Round 39 ---\n",
            "Global Round 39 completed\n",
            "--- Global Round 40 ---\n",
            "Global Round 40 completed\n",
            "--- Global Round 41 ---\n",
            "Global Round 41 completed\n",
            "--- Global Round 42 ---\n",
            "Global Round 42 completed\n",
            "--- Global Round 43 ---\n",
            "Global Round 43 completed\n",
            "--- Global Round 44 ---\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nStarting Federated Training using FedAvg\\n\")\n",
        "\n",
        "for round_num in range(NUM_ROUNDS):\n",
        "    print(f\"--- Global Round {round_num+1} ---\")\n",
        "\n",
        "    client_weights = []\n",
        "\n",
        "    # Server sends global model to clients\n",
        "    for client_id in range(NUM_CLIENTS):\n",
        "\n",
        "        # Client receives global model\n",
        "        local_model = create_dnn_model()\n",
        "        local_model.set_weights(global_model.get_weights())\n",
        "\n",
        "        # Client trains on its own data\n",
        "        local_model.fit(\n",
        "            clients_data[client_id][\"X\"],\n",
        "            clients_data[client_id][\"y\"],\n",
        "            epochs=LOCAL_EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Client sends updated model to server\n",
        "        client_weights.append(local_model.get_weights())\n",
        "\n",
        "    # Server aggregates models (FedAvg)\n",
        "    new_global_weights = fedavg(client_weights)\n",
        "    global_model.set_weights(new_global_weights)\n",
        "\n",
        "    print(f\"Global Round {round_num+1} completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZTJbSTNJPhH"
      },
      "outputs": [],
      "source": [
        "def evaluate_global_model(global_model, clients_data):\n",
        "    client_accuracies = []\n",
        "\n",
        "    for i in range(NUM_CLIENTS):\n",
        "        loss, acc = global_model.evaluate(\n",
        "            clients_data[i][\"X\"],\n",
        "            clients_data[i][\"y\"],\n",
        "            verbose=0\n",
        "        )\n",
        "        client_accuracies.append(acc)\n",
        "\n",
        "        print(f\"Client {i+1} Accuracy: {acc:.4f}\")\n",
        "\n",
        "    avg_acc = np.mean(client_accuracies)\n",
        "    print(f\"\\nAverage Client Accuracy: {avg_acc:.4f}\\n\")\n",
        "\n",
        "    return client_accuracies, avg_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlvcTwYfJQ7z"
      },
      "outputs": [],
      "source": [
        "print(\"\\nStarting Federated Training using FedAvg\\n\")\n",
        "\n",
        "for round_num in range(NUM_ROUNDS):\n",
        "    print(f\"\\n--- Global Round {round_num+1} ---\")\n",
        "\n",
        "    client_weights = []\n",
        "\n",
        "    # -------- CLIENT TRAINING --------\n",
        "    for client_id in range(NUM_CLIENTS):\n",
        "\n",
        "        local_model = create_dnn_model()\n",
        "        local_model.set_weights(global_model.get_weights())\n",
        "\n",
        "        local_model.fit(\n",
        "            clients_data[client_id][\"X\"],\n",
        "            clients_data[client_id][\"y\"],\n",
        "            epochs=LOCAL_EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        client_weights.append(local_model.get_weights())\n",
        "\n",
        "    # -------- SERVER AGGREGATION --------\n",
        "    new_global_weights = fedavg(client_weights)\n",
        "    global_model.set_weights(new_global_weights)\n",
        "\n",
        "    print(\"Evaluating global model on each client:\")\n",
        "\n",
        "    # -------- EVALUATION --------\n",
        "    evaluate_global_model(global_model, clients_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF7HX6PrSyJz"
      },
      "outputs": [],
      "source": [
        "def create_fedbn_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Input(shape=(INPUT_DIM,)),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(32, activation=\"relu\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISEofvakS-A8"
      },
      "outputs": [],
      "source": [
        "global_fedbn_model = create_fedbn_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brInVg9bSzBI"
      },
      "outputs": [],
      "source": [
        "def fedbn_aggregate(client_weights, global_model):\n",
        "    new_weights = []\n",
        "    global_weights = global_model.get_weights()\n",
        "\n",
        "    for i, layer_weights in enumerate(zip(*client_weights)):\n",
        "        # BatchNorm layers have gamma, beta, mean, variance\n",
        "        if len(layer_weights[0].shape) == 1:\n",
        "            # BN parameters → keep server copy (do not average)\n",
        "            new_weights.append(global_weights[i])\n",
        "        else:\n",
        "            # Other layers → average\n",
        "            new_weights.append(np.mean(layer_weights, axis=0))\n",
        "\n",
        "    return new_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL7TwhBvT2RU"
      },
      "outputs": [],
      "source": [
        "def evaluate_accuracy(global_model, clients_data):\n",
        "    print(\"\\nClient-wise Accuracy:\")\n",
        "\n",
        "    acc_list = []\n",
        "\n",
        "    for client_id in range(len(clients_data)):\n",
        "        X_client = clients_data[client_id][\"X\"]\n",
        "        y_client = clients_data[client_id][\"y\"]\n",
        "\n",
        "        loss, acc = global_model.evaluate(\n",
        "            X_client, y_client, verbose=0\n",
        "        )\n",
        "\n",
        "        acc_list.append(acc)\n",
        "        print(f\"Client {client_id+1}: Accuracy = {acc:.4f}\")\n",
        "\n",
        "    print(f\"\\nAverage Client Accuracy: {np.mean(acc_list):.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHLbrcgGSy9z"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# FedBN Training Loop (Improved)\n",
        "# ================================\n",
        "\n",
        "NUM_ROUNDS = 100       # Global rounds\n",
        "LOCAL_EPOCHS = 4      # Client training epochs\n",
        "BATCH_SIZE = 2028\n",
        "\n",
        "print(\"\\nStarting Federated Training using FedBN\\n\")\n",
        "\n",
        "for round_num in range(NUM_ROUNDS):\n",
        "    print(f\"--- Global Round {round_num+1} ---\")\n",
        "\n",
        "    client_weights = []\n",
        "\n",
        "    # -------- CLIENT TRAINING --------\n",
        "    for client_id in range(NUM_CLIENTS):\n",
        "        # Each client receives global model\n",
        "        local_model = create_fedbn_model()\n",
        "        local_model.set_weights(global_fedbn_model.get_weights())\n",
        "\n",
        "        # Train on local client data\n",
        "        local_model.fit(\n",
        "            clients_data[client_id][\"X\"],\n",
        "            clients_data[client_id][\"y\"],\n",
        "            epochs=LOCAL_EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Append updated weights to send back to server\n",
        "        client_weights.append(local_model.get_weights())\n",
        "\n",
        "    # -------- SERVER AGGREGATION (FedBN) --------\n",
        "    new_weights = fedbn_aggregate(client_weights, global_fedbn_model)\n",
        "    global_fedbn_model.set_weights(new_weights)\n",
        "\n",
        "    # -------- EVALUATE ACCURACY --------\n",
        "    print(\"Evaluating global model on clients:\")\n",
        "    evaluate_accuracy(global_fedbn_model, clients_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYwQA3S3Sy6L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WY71PrAaSyt7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNi6QGNuJIggHHBnCR2bkMz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}