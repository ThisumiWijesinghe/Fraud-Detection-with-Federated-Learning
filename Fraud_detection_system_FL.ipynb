{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThisumiWijesinghe/Fraud-Detection-with-Federated-Learning/blob/main/Fraud_detection_system_FL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiZ0LC5OcTj-"
      },
      "source": [
        "#Load dataset  and preprocessing part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG93FG_faxY2",
        "outputId": "12e0b912-9e67-4af0-edec-1bb70ad70ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Shape: (233392, 11)\n",
            "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
            "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
            "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
            "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
            "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
            "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
            "\n",
            "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
            "0  M1979787155             0.0             0.0      0.0             0.0  \n",
            "1  M2044282225             0.0             0.0      0.0             0.0  \n",
            "2   C553264065             0.0             0.0      1.0             0.0  \n",
            "3    C38997010         21182.0             0.0      1.0             0.0  \n",
            "4  M1230701703             0.0             0.0      0.0             0.0  \n",
            "Fraud distribution: [233234    157]\n",
            "After SMOTE: [233234 233234]\n",
            "Client 1: (31097, 7), Fraud Cases: 15476.0\n",
            "Client 2: (31097, 7), Fraud Cases: 15522.0\n",
            "Client 3: (31097, 7), Fraud Cases: 15655.0\n",
            "Client 4: (31097, 7), Fraud Cases: 15428.0\n",
            "Client 5: (31097, 7), Fraud Cases: 15513.0\n",
            "Client 6: (31097, 7), Fraud Cases: 15623.0\n",
            "Client 7: (31097, 7), Fraud Cases: 15573.0\n",
            "Client 8: (31097, 7), Fraud Cases: 15706.0\n",
            "Client 9: (31097, 7), Fraud Cases: 15575.0\n",
            "Client 10: (31097, 7), Fraud Cases: 15350.0\n",
            "Client 11: (31097, 7), Fraud Cases: 15611.0\n",
            "Client 12: (31107, 7), Fraud Cases: 15555.0\n",
            " 12 client datasets saved successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1 - Data Preparation for 12 Clients (Banks)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "\n",
        "df = pd.read_csv(\"fraud.csv\")\n",
        "\n",
        "print(\"Original Shape:\", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Drop irrelevant columns\n",
        "\n",
        "df = df.drop(['nameOrig', 'nameDest', 'isFlaggedFraud'], axis=1)\n",
        "\n",
        "# Encode 'type' column\n",
        "df['type'] = LabelEncoder().fit_transform(df['type'])\n",
        "\n",
        "# Drop rows with missing values (if any)\n",
        "df = df.dropna()\n",
        "\n",
        "\n",
        "# Features & Target\n",
        "\n",
        "X = df.drop(['isFraud'], axis=1)\n",
        "y = df['isFraud']\n",
        "\n",
        "print(\"Fraud distribution:\", np.bincount(y))\n",
        "\n",
        "\n",
        "# Handle class imbalance with SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X, y)\n",
        "\n",
        "print(\"After SMOTE:\", np.bincount(y_res))\n",
        "\n",
        "\n",
        "# Split into 12 Clients (Banks)\n",
        "\n",
        "clients_X = []\n",
        "clients_y = []\n",
        "\n",
        "X_train_global, X_test_global, y_train_global, y_test_global = train_test_split(\n",
        "    X_res, y_res, test_size=0.2, random_state=42, stratify=y_res\n",
        ")\n",
        "\n",
        "# Divide into 12 roughly equal client datasets\n",
        "split_size = len(X_train_global) // 12\n",
        "\n",
        "for i in range(12):\n",
        "    start = i * split_size\n",
        "    end = (i + 1) * split_size if i < 11 else len(X_train_global)\n",
        "\n",
        "    X_client = X_train_global[start:end]\n",
        "    y_client = y_train_global[start:end]\n",
        "\n",
        "    # Scale per-client\n",
        "    scaler = StandardScaler()\n",
        "    X_client_scaled = scaler.fit_transform(X_client)\n",
        "\n",
        "    clients_X.append(X_client_scaled)\n",
        "    clients_y.append(y_client.values)\n",
        "\n",
        "    print(f\"Client {i+1}: {X_client_scaled.shape}, Fraud Cases: {sum(y_client)}\")\n",
        "\n",
        "\n",
        "# Save datasets per client\n",
        "\n",
        "for i in range(12):\n",
        "    client_df = pd.DataFrame(clients_X[i], columns=X.columns)\n",
        "    client_df['isFraud'] = clients_y[i]\n",
        "    client_df.to_csv(f\"client_{i+1}_dataset.csv\", index=False)\n",
        "\n",
        "print(\" 12 client datasets saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myfhRHXZd_2i"
      },
      "source": [
        "#ML models training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7W14HGoeFAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e672d3a-5503-4566-8777-c878cc851fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy scikit-learn imbalanced-learn xgboost joblib matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (precision_score, recall_score, f1_score,\n",
        "                             roc_auc_score, confusion_matrix, classification_report)\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "FNVVUgSXwWbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Config\n",
        "DATA_PATH = \"fraud.csv\"\n",
        "OUTPUT_DIR = \"baseline_output\"\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.20\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "IwCozl1SwWYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load & basic preprocessing\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(\"Original shape:\", df.shape)\n",
        "\n",
        "# follow thisumi's preprocessing\n",
        "df = df.drop(['nameOrig', 'nameDest', 'isFlaggedFraud'], axis=1, errors='ignore')\n",
        "df['type'] = LabelEncoder().fit_transform(df['type'])\n",
        "df = df.dropna()\n",
        "\n",
        "X = df.drop(['isFraud'], axis=1)\n",
        "y = df['isFraud'].astype(int)\n",
        "\n",
        "print(\"Global fraud distribution (before SMOTE):\", np.bincount(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Isa60OaFwWVk",
        "outputId": "799a6223-975f-4418-af03-920119e0a95f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (655045, 11)\n",
            "Global fraud distribution (before SMOTE): [654646    398]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=RANDOM_STATE)\n",
        "X_res, y_res = smote.fit_resample(X, y)\n",
        "print(\"After SMOTE distribution:\", np.bincount(y_res))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g98ijSqwWSj",
        "outputId": "57b0c798-7b39-4f99-cfd6-cdfca319d866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After SMOTE distribution: [654646 654646]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train/test split (stratify)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_res, y_res, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_res\n",
        ")"
      ],
      "metadata": {
        "id": "Upee0tW9wWPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features (fit on train, apply to test)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "joblib.dump(scaler, os.path.join(OUTPUT_DIR, \"scaler.joblib\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKDMqCNRxcqR",
        "outputId": "2f384864-feec-48a8-df21-a78074a5c43d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['baseline_output/scaler.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# models\n",
        "models = {\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=RANDOM_STATE),\n",
        "    \"XGBoost\": XGBClassifier(n_estimators=200, use_label_encoder=False, eval_metric=\"logloss\", random_state=RANDOM_STATE)\n",
        "}\n"
      ],
      "metadata": {
        "id": "-7-9vgKfxcm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name} ...\")\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    # Save model\n",
        "    joblib.dump(model, os.path.join(OUTPUT_DIR, f\"{name}.joblib\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXi2rcWwxcfP",
        "outputId": "a32d8707-8db6-4b35-b12d-72d3ef052a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LogisticRegression ...\n",
            "\n",
            "Training RandomForest ...\n",
            "\n",
            "Training XGBoost ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:45:07] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions & scores\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "if hasattr(model, \"predict_proba\"):\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "else:\n",
        "    # fallback: decision_function to probabilities (not expected here)\n",
        "    try:\n",
        "        y_proba = model.decision_function(X_test_scaled)\n",
        "    except:\n",
        "        y_proba = y_pred\n",
        "\n",
        "precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "roc_auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "# store results\n",
        "results.append({\n",
        "    \"Model\": name,\n",
        "    \"Precision\": round(precision, 4),\n",
        "    \"Recall\": round(recall, 4),\n",
        "    \"F1\": round(f1, 4),\n",
        "    \"ROC_AUC\": round(roc_auc, 4)\n",
        "})\n",
        "\n",
        "print(f\"{name} - Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, ROC_AUC: {roc_auc:.4f}\")\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(y_test, y_pred, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdeHbRacxccW",
        "outputId": "35cca36a-7735-4069-fce9-96e5085ce112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost - Precision: 0.9976, Recall: 0.9998, F1: 0.9987, ROC_AUC: 1.0000\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9998    0.9976    0.9987    130930\n",
            "           1     0.9976    0.9998    0.9987    130929\n",
            "\n",
            "    accuracy                         0.9987    261859\n",
            "   macro avg     0.9987    0.9987    0.9987    261859\n",
            "weighted avg     0.9987    0.9987    0.9987    261859\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix plot (save)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.title(f\"Confusion Matrix - {name}\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.colorbar()\n",
        "for (i, j), v in np.ndenumerate(cm):\n",
        "    plt.text(j, i, str(v), ha='center', va='center')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, f\"confusion_{name}.png\"))\n",
        "plt.close()\n",
        "\n",
        "results.append({\n",
        "      \"model\": name,\n",
        "      \"precision\": precision,\n",
        "      \"recall\": recall,\n",
        "      \"f1\": f1,\n",
        "      \"roc_auc\": roc_auc\n",
        "  })"
      ],
      "metadata": {
        "id": "mBDtTu3GxcZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results table\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(os.path.join(OUTPUT_DIR, \"baseline_results.csv\"), index=False)\n",
        "print(\"\\nSaved baseline results to\", os.path.join(OUTPUT_DIR, \"baseline_results.csv\"))\n",
        "print(\"Saved models and confusion matrices to\", OUTPUT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjuw3k76xcWV",
        "outputId": "a769b6e8-7b69-40ca-a329-66782d3ed2cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved baseline results to baseline_output/baseline_results.csv\n",
            "Saved models and confusion matrices to baseline_output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDIFP-YteFwg"
      },
      "source": [
        "#Visualization part"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}